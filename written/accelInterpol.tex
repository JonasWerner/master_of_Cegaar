\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage{xspace}
\usepackage{tabu}
\usepackage[%
  hyperindex,%
  plainpages=false,%
  pdfusetitle]{hyperref}
\usepackage[all]{hypcap}
\usepackage{cite}
\usepackage{booktabs}
\usepackage{url}
\usepackage{listings}
\usepackage{enumitem}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{tikz}
\usetikzlibrary{positioning,shapes.geometric, arrows,automata, decorations.pathreplacing, calc}
\usepackage{pgf}
\usepackage{slantsc}
\usepackage{geometry}
\usepackage{amssymb}
\usepackage{subcaption}
\usepackage{float}
\usepackage{pgf}
\usepackage{slashbox}
\usepackage{pgfgantt}
\usepackage{wrapfig}
\usepackage{pdflscape}



\usepackage[%disable,%
  colorinlistoftodos,%
  color=cyan!50!white,%
  bordercolor=cyan!50!black]{todonotes}

%%%%%%%%%%%% Colors 
%% a somewhat friendly scheme for 5 different colors 
\definecolor{g1}		{RGB}{215,25,28} % a kind of red
\definecolor{g2}		{RGB}{253,174,97} % a kind of orange
\definecolor{g3}		{RGB}{255,255,191} % a kind of yellow
\definecolor{g4}		{RGB}{171,217,233} % a kind of light blue 
\definecolor{g5}		{RGB}{44,123,182} % a kind of dark blue 

\definecolor{gr1}		{RGB}{250, 250, 250}
\definecolor{gr2}		{RGB}{229, 229, 229} % some grey

% color of interpolants
\definecolor{grey}{RGB}{200,200,200}

%color for pictures
\colorlet{outlineblue}		{g5}
\colorlet{fillblue}			{g4}
\colorlet{darkback}			{gr2}
\colorlet{lightback}		{gr1}
\colorlet{stmtcolor}		{gr2} %default statement color
\colorlet{subgraphcolor}	{g3} %default statement color


%%%%%%%%%%%% Setup
\newtheorem{name}{Printed output}
\newtheorem{mydef}{Definition}

\hypersetup{
colorlinks=true,        % false: boxed links; true: colored links
linkcolor=g1,        % color of internal links
citecolor=g1,        % color of links to bibliography
filecolor=g1,        % color of file links
urlcolor=g1          % color of external links
}


\lstdefinestyle{boogie}{
  belowcaptionskip=1\baselineskip,
  breaklines=true,
  xleftmargin=\parindent,
  showstringspaces=false,
  basicstyle=\footnotesize\ttfamily,
  numbers=left,
  xleftmargin=.6cm
}

\lstset{escapechar=@,style=boogie}

%%%%%%%%%%%% Comments
\newif\iffinal
%\finaltrue % comment out to remove comments 
 
\iffinal
\newcommand\mycom[1]{}
\else
\newcommand\mycom[1]{#1}
\overfullrule=1mm
\fi
\setlength\parindent{0pt}

\newcommand{\WidestEntry}{$\psi_{global}$}%
\newcommand{\SetToWidest}[1]{\makebox[\widthof{\WidestEntry}]{$#1$}}%

\newcommand{\jw}[1]{\mycom{\todo[color=blue!40,inline]{\small JW: #1}}}
\newcommand{\dd}[1]{\mycom{\todo[color=orange!40,inline]{\small DD: #1}}}
\newcommand{\ts}[1]{\mycom{\todo[color=green!40,inline]{\small TS: #1}}}


\newcommand{\all}[1]{\mycom{\todo[color=green!40,inline]{\small #1}}}
\newcommand{\meta}[1]{\mycom{\todo[color=blue!10,inline,caption={Beschreibung},nolist]{\setlist{nolistsep}\small #1}}}
\newcommand{\xxx}{\mycom{\stfootcol{Placeholder}{blue!20}\xspace}}
\newcommand{\cn}{\mycom{\stfootcol{Cite}{blue!20}\xspace}}


\begin{document}
	\newcommand{\HorizontalLine}{\rule{\linewidth}{0.3mm}}
	
		\begin{center}
		{\scshape\Large Master Project \par}
		\vspace{1.5cm}
		{\huge\bfseries Accelerated Interpolation \par}
		\vspace{1cm}
		{\large \scshape Jonas Werner\par}
		\vspace{0.5cm}
		{\today \vspace{2cm}} 
		
		\end{center}

\section{Introduction}
Assume we want to verify whether a program fulfills a given safety property. The program's control-flow graph represents every possible trace that can be taken by a program execution. Executions that violate the safety property end in a so called error location. Error traces are traces in the control-flow graph that start in the initial node and end in the error location. The goal is to check if there are feasible error traces.
For this purpose one can apply an automata-based instance of the CEGAR scheme, called trace abstraction, on the program's control-flow graph. \\

Trace abstraction aims at constructing automata \cite{10.1007/978-3-642-39799-8_2} from infeasible error traces. When the language recognized by the program's control-flow graph is a subset of these automata, it means, every possible error trace, and by that execution which ends in an error location, is infeasible. Proving that the program fulfills the safety property. If there is a single feasible error trace, then the program violates the safety property.\\
\par 
If an error trace is infeasible there is an infeasibility proof. Using this proof one can construct an automaton, which excludes the original error trace from the control-flow graph. However, this excludes only one error trace, making this approach not very efficient. To exclude more than one error trace, one can try to compute a generalization of the infeasibility proof. \par

A common strategy is \cite{10.1007/978-3-642-03237-0_7} to calculate a generalization using Craig interpolation \cite{craig_1957}, where an SMT-solver computes a sequence of interpolants from an infeasibility proof. \par 
But, it is not guaranteed that these interpolants are more general. This issue is most notably in program loops. Assume that the given program contains a loop with guard $x < 5000$, $x$ being an integer variable. It is possible that the computed interpolant sequence does not exclude every loop iteration, leading to the need of disproving every of the 5000 possible error traces individually. \\ \\
A solution for this problem is accelerating the loop, meaning computing its transitive closure, and calculating interpolants on that. \par This project aims at implementing exactly that. 
The goal is to combine interpolation and loop acceleration on the basis of the work of Hojjat et al \cite{10.1007/978-3-642-33386-6_16} in the software analysis framework \\ Ultimate \cite{Zitat02}. \par
The remainder of this proposal is structured as follows. Chapter 2 will give an overview of needed background information, like a more detailed look at trace abstraction, loop acceleration, and the combination of interpolation and acceleration. Chapter 3 will detail the approach this project will take to implement accelerated interpolation in Ultimate, and finally an outline of the project's deliverables and schedule.

\section{Background}
This project aims at combining loop acceleration and interpolant calculation based on the findings of Hojjat et al. \cite{10.1007/978-3-642-33386-6_16}, however, instead of utilizing a CEGAR-scheme with predicate abstraction, it will be implemented as an automata-based CEGAR-scheme, called trace abstraction. \par
This section will introduce the basic ideas behind trace abstraction, loop acceleration, and finally accelerated interpolants.

\subsection{Interpolating Trace Abstraction}
A program $\texttt{P}$ can be represented by a control-flow graph.
\begin{mydef}
	A program $\texttt{P}$'s control-flow graph $G_P = (Loc, \Delta, \ell_{0}, \ell_{Err})$ is a tuple, where
	 \begin{itemize}
		\item $Loc$ is a set of program locations
		\item $\Delta$ is a set of triples $(\ell_i, stm_i, \ell_{i + 1})$ representing program transitions with $\ell_i, \ell_{i + 1} \in Loc$ and program statement $stm_i$.
		\item $\ell_{0}$ represents the initial location.
		\item $\ell_{Err} \subseteq Loc$ a set of error locations.
	\end{itemize}
\end{mydef}
It is possible to interpret the control-flow graph as a nondeterministic automaton. \\ 

Consider, for example, the following program $\texttt{P}$ and its corresponding control-flow graph $G_P$:

\begin{minipage}{.3\textwidth}
	\centering
	\begin{align*}
	&\texttt{1: int x := 0}; \\
	&\texttt{2: while x < 6;} \\
	&\texttt{3: \hspace*{2em} x := x + 2;} \\
	&\texttt{4: end while} \\
	&\texttt{5: assert x == 6;}
	\end{align*}
	\captionof{figure}{Program $\texttt{P}$}
	\label{fig:square}
\end{minipage}%
\hfill
\begin{minipage}{.6\textwidth}
	\centering
	\begin{tikzpicture}[%
	->,
	>=stealth', shorten >=1pt, auto,
	node distance=2.5cm, scale=1, 
	transform shape, align=center,    
	smallnode/.style={inner sep=1.4}
	initial text =]
	\node[state, initial above](1){$\ell_0$};
	
	\node[state] (2) [below of=1] {$\ell_1$};
	
	\node[state] (3) [left of=2] {$\ell_2$};
	
	\node[state] (4) [right of=2] {$\ell_3$};
	
	\node[state] (5) [below of=4] {$\ell_E$};
	
	\node[state] (6) [right of=4] {$\ell_4$};
	
	\path (1) edge node {$\texttt{x := 0}$} (2)
	(2) edge [bend right] node [above]{$\texttt{x < 6}$} (3)
	(3) edge [bend right] node [below]{$\texttt{x := x + 2}$} (2)
	(2) edge node {$\texttt{!x <= 4}$} (4)
	(4) edge node {$\texttt{x != 6}$} (5)
	(4) edge node {$\texttt{x == 6}$} (6)
	;
	\end{tikzpicture}
	\captionof{figure}{$G_P$}
	\label{fig:rect}
\end{minipage}%
\\ \vspace*{2em}

Through a control-flow graph there are so called program traces characterizing transitions from one program state to another. \\

\begin{mydef}
	Relations
	Compositions etc
\end{mydef}

\begin{mydef}
	A program trace $\tau$ is a sequence of triples $(\ell_0, \varphi_0, \ell_1), (\ell_1, \varphi_1, \ell_2), \ldots,  (\ell_{n - 1}, \varphi_{n - 1}, \ell_n),$ where each $(\ell_i, \varphi_i, \ell_{i + 1})$ consists of
	\begin{itemize}
		\item $\ell_i$ the source program location.
		\item $\varphi_i$ a first order formula in single static assignment form defining the changes to program variables during a state transition. $\varphi_i$ is called the transition formula.
		\item  $\ell_{i+1}$ the program location after the transition.
	\end{itemize}
If $\ell_n \in \ell_{Err}$ then the program trace is called error trace.
\end{mydef}
\vspace*{2em}
Program traces can be graphically represented:
\begin{figure}[H]
	\centering
	\begin{tikzpicture}[%
		->,
		>=stealth', shorten >=1pt, auto,
		node distance=2.5cm, scale=1, 
		transform shape, align=center,    
		smallnode/.style={inner sep=2}
		initial text =]
		
		\node[state](1){$\ell_0$};
		
		\node[state] (2) [right of=1] {$\ell_1$};
		
		\node[] (3) [right of=2] {$\cdots$};
		
		\node[state] (4) [right of=3] {$\ell_{n-1}$};
		
		\node[state] (5) [right of=4] {$\ell_n$};
		
		
		\path (1) edge node {$\varphi_0$} (2); 
		\path (2) edge node {$\varphi_1$} (3); 
		\path (3) edge node {$\varphi_{n-1}$} (4);
		\path (4) edge node {$\varphi_n$} (5); 
		;
	\end{tikzpicture}
	\captionof{figure}{Graphical Representation of $\tau$}
\end{figure}

Using definitions 1 and 2 we can define trace abstraction as a technique of proving or disproving safety for a given program by checking for reachability of an error location.

\begin{mydef}
	 To check reachability of an error location $\ell_E \in \ell_{Err}$, use trace abstraction with interpolation according to the following paradigm \cite{10.1007/978-3-642-03237-0_7}: \\
	 Given 	program $\texttt{P}$'s control-flow graph $G_P = (Loc, \Delta, \ell_{0}, \ell_{Err})$
	\begin{itemize}
		\item[1.] Search $G_P$ for a program trace that starts at $\ell_0$ and ends in $\ell_E$:
\begin{figure}[H]
	\centering
	\begin{tikzpicture}[%
		->,
		>=stealth', shorten >=1pt, auto,
		node distance=2.5cm, scale=1, 
		transform shape, align=center,    
		smallnode/.style={inner sep=2}
		initial text =]
		
		\node[state](1){$\ell_0$};
		
		\node[state] (2) [right of=1] {$\ell_1$};
		
		\node[] (3) [right of=2] {$\cdots$};
		
		\node[state] (4) [right of=3] {$\ell_{n-1}$};
		
		\node[state] (5) [right of=4] {$\ell_E$};
		
		
		\path (1) edge node {$\varphi_0$} (2); 
		\path (2) edge node {$\varphi_1$} (3); 
		\path (3) edge node {$\varphi_{n-1}$} (4);
		\path (4) edge node {$\varphi_n$} (5); 
		;
	\end{tikzpicture}
\end{figure}
		With each $(\ell_i, stm_i, \ell_{i + 1}) \in \Delta$.
		\item[2.] Prove feasibility. \\ In case that the trace is proven feasible, the program is incorrect, if the trace is infeasible construct an infeasibility proof.
		\item[3.] Use the infeasibility proof to calculate interpolants.
		\item[4.] Construct an automaton, $\mathcal{A}_i$, from the interpolants.
		\item[5.] If the language $\mathcal{L(A_P)}$, that is recognized by the program's control-flow graph, is a subset of the union of languages recognized by the constructed automata: $\mathcal{L(A_P)} \subseteq \mathcal{L(A}_1) \cup ... \cup \mathcal{L(A}_i)$ then the program is correct, else start again at step 1.
	\end{itemize}
\end{mydef}
	The interpolants generated in step 3 serve to generalize the infeasibility proof to exclude other possible error traces. However, the interpolants are not guaranteed to be general enough to exclude a large number of error traces. Which poses a problem for loops. In the following we introduce a way to exclude a large number of traces going through a loop.


\section{Loop Acceleration}
Programs generally contain loops, like \texttt{while} or \texttt{for} loops. These can create up to infinitely many distinct program traces. Trace abstraction has then, in the worst case, meaning the generated Craig interpolants are only general enough to disprove one trace, refute every program trace generated by the loop. A remedy to that is by computing a loop acceleration in form of the reflexive transitive closure. This chapter introduces loops as traces and relations, and how a loop relation can be used to compute a reflexive transitive closure. \\

Assume we are given the following program trace $\tau$ from the example program $P$:

\begin{figure}[H]
	\centering
	\begin{tikzpicture}[%
		->,
		>=stealth', shorten >=1pt, auto,
		node distance=3cm, scale=1, 
		transform shape, align=center,    
		smallnode/.style={inner sep=2}
		initial text =]
		
		\node[state](1){$\ell_0$};
		\node[state] (2) [right of=1] {$\ell_1$};
		\node[state] (3) [right of=2] {$\ell_2$};
		\node[state] (4) [right of=3] {$\ell_1$};
		\node[state] (5) [right of=4] {$\ell_2$};
		\node[state] (6) [below of=1] {$\ell_1$};
		\node[state] (7) [right of=6] {$\ell_2$};
		\node[state] (8) [right of=7] {$\ell_1$};
		\node[state] (9) [right of=8] {$\ell_3$};
		\node[state] (10) [right of=9] {$\ell_E$};
		
		
		\path (1) edge node {$x_0 = 0$} (2);
		\path (2) edge node {$x_0 < 6$} (3);
		\path (3) edge node {$x_1 = x_0 + 2$} (4);
		\path (4) edge node {$x_1 < 6$} (5);
		\path (5) edge node {$x_2 = x_1 + 2$} (6);
		\path (6) edge node[below] {$x_2 < 6$} (7);
		\path (7) edge node[below] {$x_3 = x_2 + 2$} (8);
		\path (8) edge node[below] {$x_3 \geq 6$} (9);
		\path (9) edge node[below] {$x_3 \neq 6$} (10);
		;
	\end{tikzpicture}
	\captionof{figure}{$\tau$}
\end{figure}
It is noticeable that program location $\ell_1$ appears repeatedly in the trace, indicating that it is an entry point for a loop. From this entry point, the so called loop head, one can extract loop traces. 
\begin{mydef}
	A looping trace $\tau_L$ is a program trace  $(\ell_0, \varphi_0, \ell_1), (\ell_1, \varphi_1, \ell_2), \ldots,  (\ell_{n - 1}, \varphi_{n - 1}, \ell_n)$, \\ where $\ell_0 = \ell_n$.
\end{mydef}
In $\tau$ there are three looping traces of varying length:  \\


\begin{figure}[H]
	\centering
		\begin{tikzpicture}[%
			->,
			>=stealth', shorten >=1pt, auto,
			node distance=3cm, scale=1, 
			transform shape, align=center,    
			smallnode/.style={inner sep=2}
			initial text =]
			
			\node[state] (2) [] {$\ell_1$};
			\node[state] (3) [right of=2] {$\ell_2$};
			\node[state] (4) [right of=3] {$\ell_1$};
			
			\path (2) edge node {$x_0 < 6$} (3);
			\path (3) edge node {$x_1 = x_0 + 2$} (4);
			;
		\end{tikzpicture}
		\captionof{figure}{$\tau_{L_1}$}
\end{figure}

\begin{figure}[H]
	\centering
	\begin{tikzpicture}[%
		->,
		>=stealth', shorten >=1pt, auto,
		node distance=3cm, scale=1, 
		transform shape, align=center,    
		smallnode/.style={inner sep=2}
		initial text =]
		
		\node[state] (2) [] {$\ell_1$};
		\node[state] (3) [right of=2] {$\ell_2$};
		\node[state] (4) [right of=3] {$\ell_1$};
		\node[state] (5) [right of=4] {$\ell_2$};
		\node[state] (6) [right of=5] {$\ell_1$};
		
		\path (2) edge node {$x_0 < 6$} (3); 
		\path (3) edge node {$x_1 = x_0 + 2$} (4);
		\path (4) edge node {$x_1 < 6$} (5);
		\path (5) edge node {$x_2 = x_1 + 2$} (6);
		;
	\end{tikzpicture}
	\captionof{figure}{$\tau_{L_2}$}
\end{figure}

\begin{figure}[H]
	\centering
	\begin{tikzpicture}[%
		->,
		>=stealth', shorten >=1pt, auto,
		node distance=3cm, scale=1, 
		transform shape, align=center,    
		smallnode/.style={inner sep=2}
		initial text =]
		
		\node[state] (2) [] {$\ell_1$};
		\node[state] (3) [right of=2] {$\ell_2$};
		\node[state] (4) [right of=3] {$\ell_1$};
		\node[state] (5) [right of=4] {$\ell_2$};
		\node[state] (6) [right of=5] {$\ell_1$};
		\node[state] (7) [below of=1] {$\ell_2$};
		\node[state] (8) [right of=7] {$\ell_1$};
		
		\path (2) edge node {$x_0 < 6$} (3);
		\path (3) edge node {$x_1 = x_0 + 2$} (4);
		\path (4) edge node {$x_1 < 6$} (5);
		\path (5) edge node {$x_2 = x_1 + 2$} (6);
		\path (6) edge node[below] {$x_2 < 6$} (7);
		\path (7) edge node[below] {$x_3 = x_2 + 2$} (8);
		;
	\end{tikzpicture}
	\captionof{figure}{$\tau_{L_3}$}
\end{figure}
These three looping traces represent the same loop but with a different number of iterations. The loop relation can be represented by $\tau_{L_1}$.
\begin{mydef}
	A minimal looping trace $\tau_{min}$ is a looping trace \\ $(\ell_0, \varphi_0, \ell_1), (\ell_1, \varphi_1, \ell_2), \ldots,  (\ell_{n - 1}, \varphi_{n - 1}, \ell_n)$, where $\ell_0$ only appears as first and last location. It represents one iteration of the loop.
\end{mydef}
In this example $\tau_{L_1}$ is the minimal looping trace. Using the minimal looping trace it is possible to formulate the effect the loop has on the program variables as a relation.
\begin{mydef}
	The loop relation is the relation describing the effect of the loop on program variables.
	Given the minimal looping trace $\tau_{min}: \\ (\ell_0, \varphi_0, \ell_1), (\ell_1, \varphi_1, \ell_2), \ldots,  (\ell_{n - 1}, \varphi_{n - 1}, \ell_n)$ the loop relation can be constructed by building the composition of all $\varphi_i$.
\end{mydef}
For $\tau_{L_1}$ the loop relation is $x_0 < 6 \land x_1 = x_0 + 2$ \\


It is however possible to contain every program trace going through a loop in a single transition relation, the so called reflexive transitive closure.
\begin{mydef}
	Given loop relation $R_L$, the reflexive transitive closure $R^*$ is a relation that includes every possible loop trace from every possible loop iteration. It is defined as follows:
	\begin{itemize}
		\item $R^* = \bigvee_{i=0}^\infty R^i$
		\item $R^i = $
		$\begin{cases}
			& \text{id} \hspace{1.5cm} \text{if}\ i = 0 \\
			& R \circ R^{i - 1} \hspace{0.5cm}\text{otherwise}
		\end{cases}$
	\end{itemize}
\end{mydef}
This reflexive transitive closure will be used in the following chapter to compute more general interpolants for trace abstraction.

\section{Accelerated Interpolation}
This section will introduce the technique of combining loop acceleration and interpolating trace abstraction. \\\\

To check the reachability of $\ell_E$ we use the trace abstraction paradigm: \\
Firstly, we need a possible error trace $\tau_0$. \\ \\

\begin{figure}[H]
\begin{tikzpicture}[%
->,
>=stealth', shorten >=1pt, auto,
node distance=2.5cm, scale=1, 
transform shape, align=center,    
smallnode/.style={inner sep=1.4}
initial text =]

\node[state](1){$\ell_0$};

\node[state] (2) [right of=1] {$\ell_1$};

\node[state] (3) [right of=2] {$\ell_2$};

\node[state] (4) [right of=3, xshift=1cm] {$\ell_1$};

\node[state] (5) [right of=4] {$\ell_3$};

\node[state] (6) [right of=5] {$\ell_E$};

\path (1) edge node {$x_0 = 0$} (2); \\
\path (2) edge node {$x_0 \leq 4$} (3); \\
\path (3) edge node {$x_1 = x_0 + 3$} (4);\\
\path (4) edge node {$x_1 > 4$} (5); \\
\path (5) edge node {$x_1 \neq 6$} (6); \\
;
\end{tikzpicture}
	\captionof{figure}{$\tau_0$}
\end{figure}

\subsection{Meta-Traces}
The transitive closure of a loop contains every trace going through it. To make use of loop acceleration, we need to pull apart the looping location $\ell_2$ by introducing so called meta-transitions of the form:
\begin{equation*}
\overset{stm_3\ \circ \ stm_4}{\overset{\curvearrowright}{\ell_2}} \Rightarrow \hspace*{1cm} \ell_2' \xrightarrow{\text{$(stm_3 \circ stm_4)^*$}} \ell_2''
\end{equation*}
Where $(stm_3 \circ stm_4)^*$ symbolizes the calculated transitive closure of the loop. \par
Using meta-transitions, we can transform our trace scheme into a meta-trace:
\begin{equation*}
\bar{\tau}: \ell_0 \xrightarrow{\text{$stm_1$}} \ell_1 \xrightarrow{\text{$stm_2$}} \ell_2' \xrightarrow{\text{$(stm_3 \circ stm_4)^*$}} \ell_2'' \xrightarrow{\text{$stm_5$}} \ell_E
\end{equation*}
The feasibility of the meta-trace is the same as the trace scheme before: \\
\begin{itemize}
	\item  If it is feasible then the original trace is feasible, making the program incorrect
	\item If it is infeasible, we can compute an interpolant sequence: \\
	\begin{equation*}
	I_{\bar{\tau}}: \langle \top, I_1, I_2', I_2'', \bot  \rangle
	\end{equation*}
\end{itemize}

To guarantee inductiveness to the loop, we have to compute the strongest post of each interpolant, that coincide with a location in the loop, and its transitive closure:
\begin{equation*}
I_{\bar{\tau}}^{post}: \langle \top, I_1, post(I_2', stm_3 \circ stm_4), \bot  \rangle
\end{equation*}
This sequence is now general enough for the trace scheme to exclude the loop.

\subsection{Branching Loops}

\section{Accelerated Interpolation in Ultimate}
\subsection{Loopdetector}
\subsubsection{Simple Loops}

\subsubsection{Nested Loops}

\subsubsection{Procedures}

\subsection{Looppreprocessor}

\subsection{Accelerated Interpolation}


\section{Experimental Results}

\section{Future Work}

\pagebreak
\addcontentsline{toc}{chapter}{Bibliography}
\bibliographystyle{plain}
\bibliography{bib}

	
\end{document}